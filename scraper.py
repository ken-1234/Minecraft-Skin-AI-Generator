import os
import time
import requests
from bs4 import BeautifulSoup

# --- [ì„¤ì • ë¶€ë¶„] ---
TARGET_BASE_URL = "https://www.minecraftskins.com/top" # ì¸ê¸° ìŠ¤í‚¨ í˜ì´ì§€
SAVE_DIR = "research_data/top_skins"                   # ì €ì¥ ê²½ë¡œ
START_PAGE = 1                                         # ì‹œì‘ í˜ì´ì§€
END_PAGE = 5                                           # ë í˜ì´ì§€ (í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 5í˜ì´ì§€ê¹Œì§€)
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Academic-Research-Project'
}

# ì €ì¥ í´ë” ìƒì„±
if not os.path.exists(SAVE_DIR):
    os.makedirs(SAVE_DIR)
    print(f"ğŸ“‚ í´ë” ìƒì„± ì™„ë£Œ: {SAVE_DIR}")

def get_skin_ids_from_page(page_num):
    """íŠ¹ì • í˜ì´ì§€ì—ì„œ ìŠ¤í‚¨ ìƒì„¸ IDë“¤ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    url = f"{TARGET_BASE_URL}/{page_num}/"
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        if response.status_code != 200:
            print(f"âŒ í˜ì´ì§€ {page_num} ì ‘ê·¼ ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
            return []

        soup = BeautifulSoup(response.text, 'html.parser')
        # Skindexì˜ ìŠ¤í‚¨ ë§í¬ íŒ¨í„´: /skin/12345678/name
        skin_links = soup.find_all('a', href=True)
        
        ids = []
        for link in skin_links:
            href = link['href']
            if href.startswith("/skin/"):
                # hrefì—ì„œ ID ìˆ«ìë§Œ ì¶”ì¶œ
                parts = href.split('/')
                if len(parts) >= 3:
                    ids.append(parts[2])
        
        return list(set(ids)) # ì¤‘ë³µ ì œê±°
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ (í˜ì´ì§€ {page_num}): {e}")
        return []

def download_skin(skin_id):
    """IDë¥¼ ì´ìš©í•´ ì‹¤ì œ ìŠ¤í‚¨ .png íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    save_path = f"{SAVE_DIR}/{skin_id}.png"
    
    # ì´ë¯¸ ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
    if os.path.exists(save_path):
        return False

    download_url = f"https://www.minecraftskins.com/skin/download/{skin_id}"
    try:
        # ì„œë²„ ë§¤ë„ˆ: 1.5ì´ˆ ì‰¬ê¸° (ë§¤ìš° ì¤‘ìš”!)
        time.sleep(1.5)
        
        resp = requests.get(download_url, headers=HEADERS, timeout=15)
        if resp.status_code == 200:
            with open(save_path, 'wb') as f:
                f.write(resp.content)
            return True
    except:
        pass
    return False

# --- [ë©”ì¸ ì‹¤í–‰ë¶€] ---
if __name__ == "__main__":
    print(f"ğŸš€ {START_PAGE}í˜ì´ì§€ë¶€í„° {END_PAGE}í˜ì´ì§€ê¹Œì§€ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    total_downloaded = 0
    
    for p in range(START_PAGE, END_PAGE + 1):
        print(f"ğŸ“„ í˜„ì¬ {p}í˜ì´ì§€ ë¶„ì„ ì¤‘...")
        skin_ids = get_skin_ids_from_page(p)
        
        print(f"ğŸ” {len(skin_ids)}ê°œì˜ ìŠ¤í‚¨ ë°œê²¬! ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        for s_id in skin_ids:
            if download_skin(s_id):
                total_downloaded += 1
                print(f"   âœ… [{total_downloaded}] ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {s_id}.png")
            else:
                # ì´ë¯¸ ìˆê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš° ì¶œë ¥ ìƒëµ (í„°ë¯¸ë„ ê¹”ë”í•˜ê²Œ ìœ ì§€)
                pass

    print(f"\nâœ¨ ì‘ì—… ì™„ë£Œ! ì´ {total_downloaded}ê°œì˜ ìƒˆë¡œìš´ ìŠ¤í‚¨ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {os.path.abspath(SAVE_DIR)}")